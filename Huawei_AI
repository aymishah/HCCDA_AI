# Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Step 2: Load Dataset
df = pd.read_csv("TUANDROMD.csv")

# Step 3: Drop Missing Values in Label
df = df.dropna(subset=["Label"])

# Step 4: Define Features and Target
X = df.drop("Label", axis=1)
y = df["Label"]

# Step 5: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Step 6: Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 7: Define and Tune Random Forest
rf = RandomForestClassifier(random_state=42)
param_grid = {
    "n_estimators": [100, 200],
    "max_depth": [10, 20, None],
    "min_samples_split": [2, 5],
}

grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=3,
    scoring="accuracy",
    verbose=1,
    n_jobs=-1
)

grid_search.fit(X_train_scaled, y_train)
best_rf = grid_search.best_estimator_

# Step 8: Make Predictions and Evaluate
y_pred = best_rf.predict(X_test_scaled)

print("‚úÖ Best Parameters:", grid_search.best_params_)
print("‚úÖ Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# ---------------------------------------------------
# üîç Step 9: EDA on Full Dataset
# ---------------------------------------------------

# 9.1 Class Distribution
plt.figure(figsize=(6, 4))
sns.countplot(x="Label", data=df)
plt.title("Class Distribution (0 = Goodware, 1 = Malware)")
plt.xlabel("Label")
plt.ylabel("Count")
plt.xticks([0, 1], ['Goodware', 'Malware'])
plt.tight_layout()
plt.show()

# 9.2 Summary Stats
print("\nüìä Basic Statistics:")
print(df.describe().T[['mean', 'std', 'min', 'max']].head(10))

# 9.3 Correlation with Label
corr = df.corr()
top_corr = corr["Label"].abs().sort_values(ascending=False)[1:11]
print("\nüîó Top 10 Correlated Features:\n", top_corr)

# 9.4 Heatmap for Top Features
plt.figure(figsize=(10, 8))
top_features = top_corr.index.tolist() + ["Label"]
sns.heatmap(df[top_features].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap of Top Features")
plt.tight_layout()
plt.show()
